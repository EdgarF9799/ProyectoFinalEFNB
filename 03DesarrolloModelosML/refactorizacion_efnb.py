# -*- coding: utf-8 -*-
"""Refactorizacion_EFNB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mE5dvujL_tgtigf5y68XzmeMaqviUEvw
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.ensemble import VotingClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import cross_val_predict
import random

class DataPreprocessor(BaseEstimator, TransformerMixin):
    def __init__(self, scaler=MinMaxScaler()):
        self.scaler = scaler

    def fit(self, X, y=None):
        self.scaler.fit(X)
        return self

    def transform(self, X, y=None):
        return self.scaler.transform(X)

class CustomModelEvaluator(BaseEstimator, TransformerMixin):
    def __init__(self, models, model_names, n_splits=10, random_state=18):
        self.models = models
        self.model_names = model_names
        self.n_splits = n_splits
        self.random_state = random_state
        self.results = pd.DataFrame(columns=['Model', 'Auc Roc', 'Accuracy', 'Precision', 'Recall', 'F1-score'])

    def fit(self, X, y):
        self.X = X
        self.y = y
        SGK = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)

        for model, name in zip(self.models, self.model_names):
            accuracy, precision, recall, f1score, auc_roc = [], [], [], [], []
            for train_index, validation_index in SGK.split(X, y):
                X_train, X_validation = X[train_index], X[validation_index]
                y_train, y_validation = y[train_index], y[validation_index]
                model.fit(X_train, y_train)
                prediction = model.predict(X_validation)
                proba_prediction = model.predict_proba(X_validation)
                auc_roc.append(roc_auc_score(y_validation, proba_prediction[:, 1]))
                accuracy.append(accuracy_score(y_validation, prediction))
                precision.append(precision_score(y_validation, prediction, average='binary'))
                recall.append(recall_score(y_validation, prediction, average='binary'))
                f1score.append(f1_score(y_validation, prediction, average='binary'))
            self.results = self.results.append({'Model': name,
                                                'Auc Roc': np.mean(auc_roc),
                                                'Accuracy': np.mean(accuracy),
                                                'Precision': np.mean(precision),
                                                'Recall': np.mean(recall),
                                                'F1-score': np.mean(f1score)}, ignore_index=True)
        return self

    def transform(self, X):
        return self.results

class CustomVotingClassifier(BaseEstimator, TransformerMixin):
    def __init__(self, models, scaler):
        self.models = models
        self.scaler = scaler

    def fit(self, X, y):
        self.scaler.fit(X)
        self.X = self.scaler.transform(X)
        for model in self.models:
            model.fit(self.X, y)
        self.voting_classifier = VotingClassifier(estimators=[('MLPClassifier', self.models[0]),
                                                              ('GaussianProcessClassifier', self.models[16]),
                                                              ('SVC', self.models[4])], voting='hard')
        self.voting_classifier.fit(self.X, y)
        return self

    def predict(self, X):
        scaled_X = self.scaler.transform(X)
        return self.voting_classifier.predict(scaled_X)

# Load data
data = pd.read_csv("/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv")

# Set options
pd.set_option('display.max_columns', None)
sns.set_style('whitegrid')

# Drop duplicates
data = data.drop_duplicates(keep='first')

# Separate features and target
X = data.drop("output", axis=1)
y = data["output"]

# Define models
models = [LogisticRegression(random_state=18), DecisionTreeClassifier(random_state=18),
          RandomForestClassifier(random_state=18), SVC(probability=True, random_state=18, kernel="linear"),
          SVC(probability=True, random_state=18, kernel="rbf"), GaussianNB(), KNeighborsClassifier(),
          GradientBoostingClassifier(random_state=18), LGBMClassifier(random_state=18, verbose=-1),
          XGBClassifier(random_state=18), CatBoostClassifier(random_state=18, verbose=False),
          AdaBoostClassifier(random_state=18), LinearDiscriminantAnalysis(),
          QuadraticDiscriminantAnalysis(), BaggingClassifier(random_state=18),
          ExtraTreesClassifier(random_state=18), GaussianProcessClassifier(random_state=18),
          MLPClassifier(random_state=18)]

model_names = ['Logistic Regression', 'Decision Trees', 'Random Forest', 'SVM (Linear)', 'SVM (RBF)',
               'Naive Bayes', 'K-Nearest Neighbors', 'Gradient Boosting', 'LightGBM', 'XGBoost', 'CatBoost',
               'AdaBoost', 'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'Bagging', 'ExtraTrees',
               'GaussianProcess', 'MLPC']

# Create pipeline
pipeline = Pipeline([
    ('preprocessor', DataPreprocessor()),
    ('evaluator', CustomModelEvaluator(models, model_names)),
    ('voting', CustomVotingClassifier(models, scaler=MinMaxScaler()))
])

# Fit and transform pipeline
pipeline.fit(X, y)

# Predict using pipeline
random_sample_index = random.randint(0, len(X) - 1)
random_sample = X.iloc[random_sample_index].values.reshape(1, -1)
predicted_label = pipeline.predict(random_sample)
true_label = y.iloc[random_sample_index]

print("Predicted Label:", predicted_label)
print("True Label:", true_label)